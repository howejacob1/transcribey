=== Cleaning up GPU processes before test ===
Checking for GPU processes...
No GPU processes found
python main.py head --dataset test_recordings
[26/Jun/2025 16:34:20] INFO - NumExpr defaulting to 16 threads.
[26/Jun/2025 16:34:23] INFO - PyTorch version 2.7.1+cu128 available.
start method: spawn
[26/Jun/2025 16:34:23] INFO - Start in mode head.
Deleted 1587 documents from the collection.
[26/Jun/2025 16:34:23] INFO - Unmarking all reserved.
[26/Jun/2025 16:34:28] INFO - NumExpr defaulting to 16 threads.
[26/Jun/2025 16:34:28] INFO - NumExpr defaulting to 16 threads.
[26/Jun/2025 16:34:28] INFO - NumExpr defaulting to 16 threads.
[26/Jun/2025 16:34:28] INFO - NumExpr defaulting to 16 threads.
[26/Jun/2025 16:34:28] INFO - NumExpr defaulting to 16 threads.
[26/Jun/2025 16:34:28] INFO - NumExpr defaulting to 16 threads.
[26/Jun/2025 16:34:28] INFO - NumExpr defaulting to 16 threads.
[26/Jun/2025 16:34:31] INFO - PyTorch version 2.7.1+cu128 available.
[26/Jun/2025 16:34:31] INFO - PyTorch version 2.7.1+cu128 available.
[26/Jun/2025 16:34:31] INFO - PyTorch version 2.7.1+cu128 available.
[26/Jun/2025 16:34:31] INFO - PyTorch version 2.7.1+cu128 available.
[26/Jun/2025 16:34:31] INFO - PyTorch version 2.7.1+cu128 available.
[26/Jun/2025 16:34:31] INFO - PyTorch version 2.7.1+cu128 available.
[26/Jun/2025 16:34:31] INFO - PyTorch version 2.7.1+cu128 available.
[26/Jun/2025 16:34:32] INFO - Connecting to bantaim@127.0.0.1:22
[26/Jun/2025 16:34:32] INFO - Connected (version 2.0, client OpenSSH_9.6p1)
[26/Jun/2025 16:34:32] INFO - Connecting to bantaim@127.0.0.1:22
[26/Jun/2025 16:34:32] INFO - Connected (version 2.0, client OpenSSH_9.6p1)
[26/Jun/2025 16:34:32] INFO - Authentication (publickey) successful!
[26/Jun/2025 16:34:32] INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!Done, connected to bantaim@127.0.0.1:22
[26/Jun/2025 16:34:32] INFO - Authentication (publickey) successful!
[26/Jun/2025 16:34:32] INFO - !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!Done, connected to bantaim@127.0.0.1:22
[26/Jun/2025 16:34:32] INFO - [chan 0] Opened sftp connection (server version 3)
[26/Jun/2025 16:34:32] INFO - [chan 0] Opened sftp connection (server version 3)
[26/Jun/2025 16:34:33] INFO - [chan 0] sftp session closed.
[26/Jun/2025 16:35:35] INFO - Received signal 15, requesting shutdown...
[26/Jun/2025 16:35:35] INFO - Received signal 15, requesting shutdown...
Loading langid_ambernet (using local cache if available)...
[26/Jun/2025 16:35:35] INFO - Received signal 15, requesting shutdown...

--- Thread Stack Dump ---

--- Stack for QueueFeederThread (ID: 123791579924160) ---
File "/usr/lib/python3.12/threading.py", line 1030, in _bootstrap
    self._bootstrap_inner()
  File "/usr/lib/python3.12/threading.py", line 1073, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.12/threading.py", line 1010, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib/python3.12/multiprocessing/queues.py", line 251, in _feed
    nwait()
  File "/usr/lib/python3.12/threading.py", line 355, in wait
    waiter.acquire()

--- Stack for Thread-2 (ID: 123791588316864) ---
File "/usr/lib/python3.12/threading.py", line 1030, in _bootstrap
    self._bootstrap_inner()
  File "/usr/lib/python3.12/threading.py", line 1073, in _bootstrap_inner
    self.run()
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/paramiko/transport.py", line 2201, in run
    ptype, m = self.packetizer.read_message()
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/paramiko/packet.py", line 496, in read_message
    header = self.read_all(self.__block_size_in, check_rekey=True)
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/paramiko/packet.py", line 322, in read_all
    x = self.__socket.recv(n)

--- Stack for QueueFeederThread (ID: 123791596709568) ---
File "/usr/lib/python3.12/threading.py", line 1030, in _bootstrap
    self._bootstrap_inner()
  File "/usr/lib/python3.12/threading.py", line 1073, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.12/threading.py", line 1010, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib/python3.12/multiprocessing/queues.py", line 251, in _feed
    nwait()
  File "/usr/lib/python3.12/threading.py", line 355, in wait
    waiter.acquire()

--- Stack for Thread-1 (_read_thread) (ID: 123792041965248) ---
File "/usr/lib/python3.12/threading.py", line 1030, in _bootstrap
    self._bootstrap_inner()
  File "/usr/lib/python3.12/threading.py", line 1073, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.12/threading.py", line 1010, in run
    self._target(*self._args, **self._kwargs)
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 191, in _read_thread
    job_id, data = _recv_msg(self.read_pipe)
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 55, in _recv_msg
    job_id, length = _unpack_msg(read_pipe.read(msg_bytes))

--- Stack for pymongo_server_rtt_thread (ID: 123793708152512) ---
File "/usr/lib/python3.12/threading.py", line 1030, in _bootstrap
    self._bootstrap_inner()
  File "/usr/lib/python3.12/threading.py", line 1073, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.12/threading.py", line 1010, in run
    self._target(*self._args, **self._kwargs)
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/pymongo/periodic_executor.py", line 252, in _run
    time.sleep(self._min_interval)

--- Stack for pymongo_kill_cursors_thread (ID: 123793785743040) ---
File "/usr/lib/python3.12/threading.py", line 1030, in _bootstrap
    self._bootstrap_inner()
  File "/usr/lib/python3.12/threading.py", line 1073, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.12/threading.py", line 1010, in run
    self._target(*self._args, **self._kwargs)
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/pymongo/periodic_executor.py", line 252, in _run
    time.sleep(self._min_interval)

--- Stack for pymongo_server_monitor_thread (ID: 123793794135744) ---
File "/usr/lib/python3.12/threading.py", line 1030, in _bootstrap
    self._bootstrap_inner()
  File "/usr/lib/python3.12/threading.py", line 1073, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.12/threading.py", line 1010, in run
    self._target(*self._args, **self._kwargs)
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/pymongo/periodic_executor.py", line 236, in _run
    if not self._target():
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/pymongo/synchronous/monitor.py", line 80, in target
    monitor._run()  # type:ignore[attr-defined]
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/pymongo/synchronous/monitor.py", line 214, in _run
    self._server_description = self._check_server()
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/pymongo/synchronous/monitor.py", line 260, in _check_server
    return self._check_once()
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/pymongo/synchronous/monitor.py", line 326, in _check_once
    response, round_trip_time = self._check_with_socket(conn)
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/pymongo/synchronous/monitor.py", line 360, in _check_with_socket
    response = Hello(conn._next_reply(), awaitable=True)
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/pymongo/synchronous/pool.py", line 347, in _next_reply
    reply = self.receive_message(None)
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/pymongo/synchronous/pool.py", line 467, in receive_message
    return receive_message(self, request_id, self.max_message_size)
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/pymongo/network_layer.py", line 759, in receive_message
    length, _, response_to, op_code = _UNPACK_HEADER(receive_data(conn, 16, deadline))
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/pymongo/network_layer.py", line 353, in receive_data
    chunk_length = conn.conn.recv_into(mv[bytes_read:])
  File "/home/bantaim/conserver/transcribey/.venv/lib/python3.12/site-packages/pymongo/network_layer.py", line 469, in recv_into
    return self.conn.recv_into(buffer)

--- Stack for MainThread (ID: 123801397518464) ---
File "<string>", line 1, in <module>
  File "/usr/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/usr/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/bantaim/conserver/transcribey/process.py", line 30, in process_wrapper_with_signal_handlers
    return target(*args)
  File "/home/bantaim/conserver/transcribey/reserver.py", line 42, in reserver
    dump_thread_stacks()
  File "/home/bantaim/conserver/transcribey/utils.py", line 152, in dump_thread_stacks
    stack_trace = "".join(traceback.format_stack(frame))
--- End of Thread Stack Dump ---

[26/Jun/2025 16:35:35] INFO - [chan 0] sftp session closed.
[26/Jun/2025 16:35:35] INFO - Received signal 15, requesting shutdown...
[26/Jun/2025 16:35:35] INFO - Received signal 15, requesting shutdown...
LANG_DETECT: Received shutdown signal, cleaning up...
CLEANUP: Cleaning up lang_detect_model
CLEANUP: lang_detect_model deleted
CLEANUP: Starting comprehensive cleanup
CLEANUP: Cleaning up GPU memory
CLEANUP: GPU memory cleared
CLEANUP: Running garbage collection
CLEANUP: Garbage collection completed
CLEANUP: Comprehensive cleanup completed
TRANSCRIBE auto: Received shutdown signal, cleaning up...
CLEANUP: Cleaning up transcribe_model_auto
CLEANUP: transcribe_model_auto deleted
CLEANUP: Starting comprehensive cleanup
CLEANUP: Cleaning up GPU memory
CLEANUP: GPU memory cleared
CLEANUP: Running garbage collection
CLEANUP: Garbage collection completed
CLEANUP: Comprehensive cleanup completed
python main.py dump_jsonl
[26/Jun/2025 16:35:44] INFO - NumExpr defaulting to 16 threads.
[26/Jun/2025 16:35:47] INFO - PyTorch version 2.7.1+cu128 available.
start method: spawn
[26/Jun/2025 16:35:47] INFO - Start in mode dump_jsonl.
=== Cleaning up GPU processes after test ===
Checking for GPU processes...
Found GPU processes with PIDs: 265862
Killing GPU processes...
Killing process 265862
GPU process cleanup completed
🟢 avg                          |  323.99x   1,587.0    17.7/s      4.94MB/s |     442.77MB         483.5m | ( 100.0%)
⚪ transcribe_en.MainThread     |  743.88x   1,570.0    40.7/s     11.35MB/s |     437.66MB         478.0m | (  47.4%)
⚪ transcribe_non_en.MainThread |   14.46x      17.0     0.7/s      0.22MB/s |       5.11MB           5.6m | (  28.5%)
⚪ lang_detect.MainThread       | 1235.61x   1,587.0    67.6/s     18.86MB/s |     442.77MB         483.5m | (  29.0%)
🟢 preprocess.MainThread        |  524.50x   1,587.0    28.7/s      8.00MB/s |     442.77MB         483.5m | (  68.3%)
⚪ reserver.MainThread          |    0.00x   1,587.0    33.0/s      9.21MB/s |     442.77MB           0.0m | (  59.5%)
🔴 discover.MainThread          |    0.00x   1,587.0  1070.2/s    298.59MB/s |     442.77MB           0.0m | ( 100.0%)
⚪ send_results.MainThread      | 428404.42x   1,587.0 23433.6/s   6537.92MB/s |     442.77MB         483.5m | (   0.1%)
Mem: 4.0MB/12,227.0MB (0.0%) | Load: 0.0% | Temp: 42.0°C
